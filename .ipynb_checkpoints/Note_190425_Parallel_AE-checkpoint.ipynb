{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:13.420396Z",
     "start_time": "2019-04-25T22:15:12.778394Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:13.425629Z",
     "start_time": "2019-04-25T22:15:13.422882Z"
    }
   },
   "outputs": [],
   "source": [
    "#os.environ[\"WORLD_SIZE\"]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:14.035888Z",
     "start_time": "2019-04-25T22:15:13.970872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--multiprocessing-distributed'], dest='multiprocessing_distributed', nargs=0, const=True, default=False, type=None, choices=None, help='Use multi-processing distributed training to launch N processes per node, which has N GPUs. This is the fastest way to use PyTorch for either single node or multi node data parallel training', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                        ' | '.join(model_names) +\n",
    "                        ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=None, type=int,\n",
    "                    help='GPU id to use.')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One node, multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:14.493047Z",
     "start_time": "2019-04-25T22:15:14.487316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(arch='resnet50', batch_size=256, data='/scratch/by783/DL_Final/ssl_data_96', dist_backend=\"'nccl'\", dist_url=\"'tcp://127.0.0.1:FREEPORT'\", epochs=90, evaluate=False, gpu=None, lr=0.01, momentum=0.9, multiprocessing_distributed=True, pretrained=False, print_freq=10, rank=0, resume='', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_args(\"-a resnet50 --lr 0.01 --dist-url 'tcp://127.0.0.1:FREEPORT' --dist-backend 'nccl' --multiprocessing-distributed --world-size 1 --rank 0 /scratch/by783/DL_Final/ssl_data_96\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple node, multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.006235Z",
     "start_time": "2019-04-25T22:15:15.001122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(arch='resnet50', batch_size=256, data='/scratch/by783/DL_Final/ssl_data_96', dist_backend=\"'nccl'\", dist_url=\"'tcp://IP_OF_NODE0:FREEPORT'\", epochs=90, evaluate=False, gpu=None, lr=0.01, momentum=0.9, multiprocessing_distributed=True, pretrained=False, print_freq=10, rank=0, resume='', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_args(\"-a resnet50 --lr 0.01 --dist-url 'tcp://IP_OF_NODE0:FREEPORT' --dist-backend 'nccl' --multiprocessing-distributed --world-size 2 --rank 0 /scratch/by783/DL_Final/ssl_data_96\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.208287Z",
     "start_time": "2019-04-25T22:15:15.203103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(arch='resnet50', batch_size=256, data='/scratch/by783/DL_Final/ssl_data_96', dist_backend=\"'nccl'\", dist_url=\"'tcp://IP_OF_NODE0:FREEPORT'\", epochs=90, evaluate=False, gpu=None, lr=0.01, momentum=0.9, multiprocessing_distributed=True, pretrained=False, print_freq=10, rank=1, resume='', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_args(\"-a resnet50 --lr 0.01 --dist-url 'tcp://IP_OF_NODE0:FREEPORT' --dist-backend 'nccl' --multiprocessing-distributed --world-size 2 --rank 1 /scratch/by783/DL_Final/ssl_data_96\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.476842Z",
     "start_time": "2019-04-25T22:15:15.387072Z"
    }
   },
   "outputs": [],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.577573Z",
     "start_time": "2019-04-25T22:15:15.574434Z"
    }
   },
   "outputs": [],
   "source": [
    "args_world_size = ngpus_per_node*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.756268Z",
     "start_time": "2019-04-25T22:15:15.753553Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:15.924785Z",
     "start_time": "2019-04-25T22:15:15.920646Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path='/scratch/by783/DL_Final_models/'+'try'#+'190424_vgg_ae'#args.save\n",
    "model_name = 'vgg'#args.model\n",
    "num_epochs = 2 #args.epochs\n",
    "feature_extract = True # str2bool(args.pretrained)\n",
    "\n",
    "###################### fixed_params ###################################\n",
    "\n",
    "num_classes = 1000\n",
    "loader_image_path='/scratch/by783/DL_Final/ssl_data_96'\n",
    "loader_batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:16.093120Z",
     "start_time": "2019-04-25T22:15:16.082004Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_loader(path, batch_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            #transforms.Resize(input_size),\n",
    "            #transforms.CenterCrop(input_size),\n",
    "            # use model fitted with the image size, so no need to resize\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            # https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "            # [mean],[std] for different channels\n",
    "        ]\n",
    "    )\n",
    "    sup_train_data = datasets.ImageFolder('{}/{}/train'.format(path, 'supervised'), transform=transform)\n",
    "    sup_val_data = datasets.ImageFolder('{}/{}/val'.format(path, 'supervised'), transform=transform)\n",
    "    unsup_data = datasets.ImageFolder('{}/{}/'.format(path, 'unsupervised'), transform=transform)\n",
    "    # source code: https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n",
    "    # Main idea:\n",
    "    data_loader_sup_train = torch.utils.data.DataLoader(\n",
    "        sup_train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    data_loader_sup_val = torch.utils.data.DataLoader(\n",
    "        sup_val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    data_loader_unsup = torch.utils.data.DataLoader(\n",
    "        unsup_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print('sup_train_data.class_to_idx==sup_val_data.class_to_idx: ',\n",
    "          sup_train_data.class_to_idx == sup_val_data.class_to_idx)\n",
    "\n",
    "    return data_loader_sup_train, data_loader_sup_val, data_loader_unsup, sup_train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:16.280136Z",
     "start_time": "2019-04-25T22:15:16.259346Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37837682/python-class-input-argument/37837766\n",
    "# https://github.com/awentzonline/pytorch-cns/blob/master/examples/vggmse.py\n",
    "\n",
    "class Model_Based_Autoencoder(torch.nn.Module):\n",
    "    def __init__(self,model_name, pretrained):\n",
    "        super(Model_Based_Autoencoder, self).__init__()\n",
    "        if model_name!='vgg':\n",
    "            sys.stdout.write('Dear, we only support vgg now...')\n",
    "        \n",
    "        self.encoder = models.vgg11_bn(pretrained=pretrained).features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512,512,kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),#de-conv8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(512,512,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#de-conv7\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(512,512,kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),#de-conv6\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(512,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#de-conv5\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256,256,kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),#de-conv4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256,128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#de-conv3\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128,64,kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),#de-conv2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64,3,kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)),#de-conv1\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:16.430610Z",
     "start_time": "2019-04-25T22:15:16.423031Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_model(model_name, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "\n",
    "\n",
    "    if model_name != \"vgg\":\n",
    "        sys.stdout.write('We only have vgg now!!!')\n",
    "    else:\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = Model_Based_Autoencoder('vgg', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft.encoder, feature_extract)\n",
    "\n",
    "        input_size = 96\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:16.646276Z",
     "start_time": "2019-04-25T22:15:16.624907Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    #unsupervised learning, we do not need train and vals\n",
    "    since = time.time()\n",
    "    loss_history=[]\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        ################# train the model on unsupervised data ############\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, _ in dataloaders['unlabeled']:\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        epoch_loss = running_loss / len(dataloaders['unlabeled'].dataset)\n",
    "        sys.stdout.write('Training time: {:.0f}s'.format( time.time() - since ))\n",
    "        sys.stdout.write('Training loss: {:.4f}'.format(epoch_loss))\n",
    "        ################# evaluate the model performance on labeled data ############\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        eval_loss=0.0\n",
    "        for inputs, _ in dataloaders['labeled']:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            eval_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        epoch_eval_loss = running_loss / len(dataloaders['labeled'].dataset)\n",
    "        sys.stdout.write('Evaluation time: {:.0f}s'.format( time.time() - since ))        \n",
    "        sys.stdout.write(' Eval loss: {:.4f}'.format( epoch_eval_loss))\n",
    "        \n",
    "        #################\n",
    "        \n",
    "        loss_history.append( ( epoch_loss,epoch_eval_loss ) )\n",
    "        \n",
    "        \n",
    "        if epoch_eval_loss < best_loss:\n",
    "            best_loss = epoch_eval_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            with open(save_path, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            \n",
    "        with open(save_path+'_val_acc', 'w') as f:\n",
    "            for item in loss_history:\n",
    "                f.write(\"unlabeled: %s, labeled: %s \\n,  \" % (item[0],item[1]) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:16.823113Z",
     "start_time": "2019-04-25T22:15:16.818428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:21.170952Z",
     "start_time": "2019-04-25T22:15:17.001401Z"
    }
   },
   "outputs": [],
   "source": [
    "use_pretrained=True\n",
    "\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft.encoder[0].weight.requires_grad\n",
    "\n",
    "model_ft.decoder[0].weight.requires_grad\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_ft = nn.DataParallel(model_ft)\n",
    "\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:26:57.049753Z",
     "start_time": "2019-04-25T21:26:57.036601Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:26:57.427005Z",
     "start_time": "2019-04-25T21:26:57.407445Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:21.178912Z",
     "start_time": "2019-04-25T22:15:21.173882Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "learning_rate=0.001\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=learning_rate, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:15:26.951350Z",
     "start_time": "2019-04-25T22:15:21.181520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load data...sup_train_data.class_to_idx==sup_val_data.class_to_idx:  True\n"
     ]
    }
   ],
   "source": [
    "####### load data, input_size is used ####\n",
    "\n",
    "sys.stdout.write('Begin to load data...')\n",
    "\n",
    "dataloaders={}\n",
    "\n",
    "dataloaders['unlabeled'], dataloaders['labeled'], data_loader_unsup, class_to_idx_dict = image_loader(loader_image_path,loader_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-25T22:15:18.043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\tmodule.decoder.0.weight\tmodule.decoder.0.bias\tmodule.decoder.1.weight\tmodule.decoder.1.bias\tmodule.decoder.3.weight\tmodule.decoder.3.bias\tmodule.decoder.4.weight\tmodule.decoder.4.bias\tmodule.decoder.6.weight\tmodule.decoder.6.bias\tmodule.decoder.7.weight\tmodule.decoder.7.bias\tmodule.decoder.9.weight\tmodule.decoder.9.bias\tmodule.decoder.10.weight\tmodule.decoder.10.bias\tmodule.decoder.12.weight\tmodule.decoder.12.bias\tmodule.decoder.13.weight\tmodule.decoder.13.bias\tmodule.decoder.15.weight\tmodule.decoder.15.bias\tmodule.decoder.16.weight\tmodule.decoder.16.bias\tmodule.decoder.18.weight\tmodule.decoder.18.bias\tmodule.decoder.19.weight\tmodule.decoder.19.bias\tmodule.decoder.21.weight\tmodule.decoder.21.bias\tmodule.decoder.22.weight\tmodule.decoder.22.bias"
     ]
    }
   ],
   "source": [
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            sys.stdout.write(\"\\t{}\".format(name))\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            sys.stdout.write(\"\\t{}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-25T22:15:18.261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "Training time: 1563sTraining loss: 1.3153"
     ]
    }
   ],
   "source": [
    "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:12:54.768289Z",
     "start_time": "2019-04-25T22:12:43.835Z"
    }
   },
   "outputs": [],
   "source": [
    "print(adsfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:12:54.769929Z",
     "start_time": "2019-04-25T22:12:43.842Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './dc_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './conv_autoencoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
