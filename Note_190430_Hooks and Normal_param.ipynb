{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T20:49:41.642064Z",
     "start_time": "2019-05-01T20:49:41.607693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/by783/Self_Jupyter/DL_Final_Project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data mean and std\n",
    "Ref: https://discuss.pytorch.org/t/computing-the-mean-and-std-of-dataset/34949\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:46:17.816596Z",
     "start_time": "2019-05-02T01:46:17.808715Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:46:18.770268Z",
     "start_time": "2019-05-02T01:46:18.754671Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:05:01.165004Z",
     "start_time": "2019-05-01T21:05:01.160447Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:05:09.685790Z",
     "start_time": "2019-05-01T21:05:03.122619Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_image_path='/scratch/by783/DL_Final/ssl_data_96'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "sup_train_data = datasets.ImageFolder('{}/{}/train'.format(loader_image_path, 'supervised'), transform=transform)\n",
    "sup_val_data = datasets.ImageFolder('{}/{}/val'.format(loader_image_path, 'supervised'), transform=transform)\n",
    "unsup_data = datasets.ImageFolder('{}/{}/'.format(loader_image_path, 'unsupervised'), transform=transform)\n",
    "\n",
    "data_loader_sup_train = torch.utils.data.DataLoader(\n",
    "        sup_train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "data_loader_sup_val = torch.utils.data.DataLoader(\n",
    "        sup_val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "data_loader_unsup = torch.utils.data.DataLoader(\n",
    "        unsup_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:17:30.580290Z",
     "start_time": "2019-05-01T21:17:30.573859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_sup_train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:21:43.309563Z",
     "start_time": "2019-05-01T21:19:34.885091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor([0.4980, 0.4755, 0.4279])\n",
      "std:  tensor([0.2300, 0.2242, 0.2246])\n",
      "mean:  tensor([0.5002, 0.4791, 0.4320])\n",
      "std:  tensor([0.2297, 0.2236, 0.2270])\n",
      "mean:  tensor([0.4999, 0.4775, 0.4313])\n",
      "std:  tensor([0.2280, 0.2230, 0.2264])\n",
      "mean:  tensor([0.5034, 0.4780, 0.4287])\n",
      "std:  tensor([0.2282, 0.2226, 0.2247])\n",
      "mean:  tensor([0.5003, 0.4741, 0.4256])\n",
      "std:  tensor([0.2260, 0.2209, 0.2226])\n",
      "mean:  tensor([0.5014, 0.4752, 0.4286])\n",
      "std:  tensor([0.2262, 0.2225, 0.2242])\n",
      "mean:  tensor([0.5014, 0.4772, 0.4305])\n",
      "std:  tensor([0.2255, 0.2226, 0.2252])\n",
      "mean:  tensor([0.5019, 0.4773, 0.4305])\n",
      "std:  tensor([0.2258, 0.2222, 0.2253])\n",
      "mean:  tensor([0.5014, 0.4758, 0.4289])\n",
      "std:  tensor([0.2270, 0.2233, 0.2261])\n",
      "mean:  tensor([0.5037, 0.4784, 0.4309])\n",
      "std:  tensor([0.2261, 0.2227, 0.2258])\n",
      "mean:  tensor([0.5021, 0.4778, 0.4295])\n",
      "std:  tensor([0.2260, 0.2227, 0.2257])\n",
      "mean:  tensor([0.5004, 0.4751, 0.4259])\n",
      "std:  tensor([0.2261, 0.2228, 0.2258])\n",
      "mean:  tensor([0.5011, 0.4746, 0.4254])\n",
      "std:  tensor([0.2266, 0.2229, 0.2261])\n",
      "mean:  tensor([0.5002, 0.4746, 0.4261])\n",
      "std:  tensor([0.2257, 0.2221, 0.2259])\n",
      "mean:  tensor([0.5011, 0.4767, 0.4278])\n",
      "std:  tensor([0.2255, 0.2225, 0.2263])\n",
      "mean:  tensor([0.5016, 0.4766, 0.4283])\n",
      "std:  tensor([0.2257, 0.2225, 0.2262])\n",
      "mean:  tensor([0.5003, 0.4750, 0.4270])\n",
      "std:  tensor([0.2258, 0.2223, 0.2258])\n",
      "mean:  tensor([0.5000, 0.4750, 0.4270])\n",
      "std:  tensor([0.2263, 0.2228, 0.2259])\n",
      "mean:  tensor([0.4997, 0.4741, 0.4256])\n",
      "std:  tensor([0.2263, 0.2228, 0.2258])\n",
      "mean:  tensor([0.5014, 0.4746, 0.4258])\n",
      "std:  tensor([0.2262, 0.2225, 0.2257])\n",
      "mean:  tensor([0.5017, 0.4747, 0.4256])\n",
      "std:  tensor([0.2261, 0.2224, 0.2256])\n",
      "mean:  tensor([0.5015, 0.4744, 0.4258])\n",
      "std:  tensor([0.2266, 0.2224, 0.2256])\n",
      "mean:  tensor([0.5018, 0.4743, 0.4259])\n",
      "std:  tensor([0.2271, 0.2227, 0.2259])\n",
      "mean:  tensor([0.5026, 0.4745, 0.4257])\n",
      "std:  tensor([0.2268, 0.2224, 0.2255])\n",
      "mean:  tensor([0.5024, 0.4742, 0.4258])\n",
      "std:  tensor([0.2265, 0.2221, 0.2255])\n",
      "mean:  tensor([0.5029, 0.4748, 0.4265])\n",
      "std:  tensor([0.2266, 0.2220, 0.2254])\n",
      "mean:  tensor([0.5024, 0.4745, 0.4266])\n",
      "std:  tensor([0.2266, 0.2220, 0.2255])\n",
      "mean:  tensor([0.5025, 0.4741, 0.4262])\n",
      "std:  tensor([0.2269, 0.2222, 0.2258])\n",
      "mean:  tensor([0.5028, 0.4745, 0.4263])\n",
      "std:  tensor([0.2268, 0.2221, 0.2260])\n",
      "mean:  tensor([0.5024, 0.4744, 0.4267])\n",
      "std:  tensor([0.2270, 0.2223, 0.2261])\n",
      "mean:  tensor([0.5025, 0.4745, 0.4269])\n",
      "std:  tensor([0.2272, 0.2224, 0.2265])\n",
      "mean:  tensor([0.5034, 0.4752, 0.4275])\n",
      "std:  tensor([0.2271, 0.2223, 0.2264])\n",
      "mean:  tensor([0.5035, 0.4752, 0.4277])\n",
      "std:  tensor([0.2271, 0.2223, 0.2265])\n",
      "mean:  tensor([0.5033, 0.4752, 0.4277])\n",
      "std:  tensor([0.2272, 0.2223, 0.2264])\n",
      "mean:  tensor([0.5031, 0.4750, 0.4277])\n",
      "std:  tensor([0.2270, 0.2221, 0.2261])\n",
      "mean:  tensor([0.5029, 0.4753, 0.4280])\n",
      "std:  tensor([0.2272, 0.2223, 0.2263])\n",
      "mean:  tensor([0.5028, 0.4751, 0.4279])\n",
      "std:  tensor([0.2272, 0.2223, 0.2263])\n",
      "mean:  tensor([0.5021, 0.4745, 0.4272])\n",
      "std:  tensor([0.2273, 0.2224, 0.2264])\n",
      "mean:  tensor([0.5017, 0.4740, 0.4267])\n",
      "std:  tensor([0.2272, 0.2221, 0.2261])\n",
      "mean:  tensor([0.5018, 0.4743, 0.4272])\n",
      "std:  tensor([0.2270, 0.2220, 0.2261])\n",
      "mean:  tensor([0.5021, 0.4743, 0.4271])\n",
      "std:  tensor([0.2270, 0.2220, 0.2259])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-718e221ee428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#if i%10==0: print(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch size (the last batch can have smaller size!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = data_loader_sup_train\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "i=0\n",
    "sample_num=0\n",
    "\n",
    "for images, _ in loader:\n",
    "    #if i%10==0: print(10)\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    \n",
    "    sample_num+=batch_samples\n",
    "    print('mean: ',mean/sample_num)\n",
    "    print('std: ',std/sample_num)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:25:39.307734Z",
     "start_time": "2019-05-01T21:22:10.895556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor([0.5197, 0.4802, 0.4259])\n",
      "std:  tensor([0.2335, 0.2296, 0.2397])\n",
      "mean:  tensor([0.5198, 0.4824, 0.4336])\n",
      "std:  tensor([0.2308, 0.2277, 0.2368])\n",
      "mean:  tensor([0.5122, 0.4791, 0.4254])\n",
      "std:  tensor([0.2262, 0.2243, 0.2307])\n",
      "mean:  tensor([0.5133, 0.4819, 0.4311])\n",
      "std:  tensor([0.2265, 0.2241, 0.2296])\n",
      "mean:  tensor([0.5090, 0.4750, 0.4238])\n",
      "std:  tensor([0.2243, 0.2210, 0.2261])\n",
      "mean:  tensor([0.5073, 0.4742, 0.4228])\n",
      "std:  tensor([0.2257, 0.2218, 0.2267])\n",
      "mean:  tensor([0.5041, 0.4725, 0.4224])\n",
      "std:  tensor([0.2258, 0.2219, 0.2276])\n",
      "mean:  tensor([0.5047, 0.4739, 0.4239])\n",
      "std:  tensor([0.2260, 0.2224, 0.2279])\n",
      "mean:  tensor([0.5044, 0.4740, 0.4245])\n",
      "std:  tensor([0.2257, 0.2223, 0.2276])\n",
      "mean:  tensor([0.5041, 0.4739, 0.4243])\n",
      "std:  tensor([0.2260, 0.2226, 0.2278])\n",
      "mean:  tensor([0.5031, 0.4722, 0.4229])\n",
      "std:  tensor([0.2266, 0.2233, 0.2283])\n",
      "mean:  tensor([0.5029, 0.4715, 0.4215])\n",
      "std:  tensor([0.2265, 0.2230, 0.2278])\n",
      "mean:  tensor([0.5035, 0.4723, 0.4228])\n",
      "std:  tensor([0.2262, 0.2230, 0.2280])\n",
      "mean:  tensor([0.5039, 0.4729, 0.4231])\n",
      "std:  tensor([0.2258, 0.2230, 0.2283])\n",
      "mean:  tensor([0.5034, 0.4723, 0.4222])\n",
      "std:  tensor([0.2261, 0.2233, 0.2285])\n",
      "mean:  tensor([0.5031, 0.4720, 0.4221])\n",
      "std:  tensor([0.2261, 0.2229, 0.2278])\n",
      "mean:  tensor([0.5031, 0.4732, 0.4245])\n",
      "std:  tensor([0.2262, 0.2227, 0.2278])\n",
      "mean:  tensor([0.5028, 0.4724, 0.4240])\n",
      "std:  tensor([0.2265, 0.2231, 0.2280])\n",
      "mean:  tensor([0.5016, 0.4711, 0.4221])\n",
      "std:  tensor([0.2264, 0.2229, 0.2277])\n",
      "mean:  tensor([0.5027, 0.4724, 0.4238])\n",
      "std:  tensor([0.2260, 0.2224, 0.2273])\n",
      "mean:  tensor([0.5024, 0.4726, 0.4246])\n",
      "std:  tensor([0.2258, 0.2223, 0.2272])\n",
      "mean:  tensor([0.5027, 0.4729, 0.4248])\n",
      "std:  tensor([0.2258, 0.2221, 0.2268])\n",
      "mean:  tensor([0.5036, 0.4739, 0.4259])\n",
      "std:  tensor([0.2263, 0.2225, 0.2272])\n",
      "mean:  tensor([0.5040, 0.4748, 0.4273])\n",
      "std:  tensor([0.2266, 0.2228, 0.2274])\n",
      "mean:  tensor([0.5031, 0.4740, 0.4263])\n",
      "std:  tensor([0.2266, 0.2227, 0.2273])\n",
      "mean:  tensor([0.5024, 0.4730, 0.4250])\n",
      "std:  tensor([0.2264, 0.2224, 0.2268])\n",
      "mean:  tensor([0.5021, 0.4729, 0.4255])\n",
      "std:  tensor([0.2265, 0.2225, 0.2272])\n",
      "mean:  tensor([0.5023, 0.4727, 0.4252])\n",
      "std:  tensor([0.2266, 0.2226, 0.2271])\n",
      "mean:  tensor([0.5031, 0.4728, 0.4246])\n",
      "std:  tensor([0.2268, 0.2231, 0.2273])\n",
      "mean:  tensor([0.5031, 0.4731, 0.4250])\n",
      "std:  tensor([0.2272, 0.2233, 0.2271])\n",
      "mean:  tensor([0.5036, 0.4733, 0.4253])\n",
      "std:  tensor([0.2276, 0.2236, 0.2273])\n",
      "mean:  tensor([0.5033, 0.4731, 0.4251])\n",
      "std:  tensor([0.2276, 0.2236, 0.2275])\n",
      "mean:  tensor([0.5039, 0.4740, 0.4262])\n",
      "std:  tensor([0.2275, 0.2235, 0.2273])\n",
      "mean:  tensor([0.5039, 0.4741, 0.4264])\n",
      "std:  tensor([0.2275, 0.2236, 0.2276])\n",
      "mean:  tensor([0.5045, 0.4744, 0.4270])\n",
      "std:  tensor([0.2281, 0.2241, 0.2281])\n",
      "mean:  tensor([0.5039, 0.4740, 0.4268])\n",
      "std:  tensor([0.2278, 0.2238, 0.2279])\n",
      "mean:  tensor([0.5032, 0.4731, 0.4262])\n",
      "std:  tensor([0.2280, 0.2239, 0.2280])\n",
      "mean:  tensor([0.5024, 0.4723, 0.4254])\n",
      "std:  tensor([0.2277, 0.2234, 0.2275])\n",
      "mean:  tensor([0.5025, 0.4724, 0.4253])\n",
      "std:  tensor([0.2278, 0.2235, 0.2275])\n",
      "mean:  tensor([0.5026, 0.4725, 0.4253])\n",
      "std:  tensor([0.2278, 0.2235, 0.2274])\n",
      "mean:  tensor([0.5027, 0.4730, 0.4259])\n",
      "std:  tensor([0.2278, 0.2235, 0.2275])\n",
      "mean:  tensor([0.5030, 0.4732, 0.4261])\n",
      "std:  tensor([0.2278, 0.2236, 0.2276])\n",
      "mean:  tensor([0.5026, 0.4729, 0.4261])\n",
      "std:  tensor([0.2280, 0.2236, 0.2278])\n",
      "mean:  tensor([0.5026, 0.4729, 0.4258])\n",
      "std:  tensor([0.2277, 0.2233, 0.2275])\n",
      "mean:  tensor([0.5023, 0.4728, 0.4258])\n",
      "std:  tensor([0.2276, 0.2232, 0.2273])\n",
      "mean:  tensor([0.5029, 0.4735, 0.4266])\n",
      "std:  tensor([0.2277, 0.2233, 0.2275])\n",
      "mean:  tensor([0.5027, 0.4735, 0.4269])\n",
      "std:  tensor([0.2274, 0.2230, 0.2271])\n",
      "mean:  tensor([0.5028, 0.4737, 0.4269])\n",
      "std:  tensor([0.2273, 0.2230, 0.2271])\n",
      "mean:  tensor([0.5024, 0.4732, 0.4263])\n",
      "std:  tensor([0.2273, 0.2229, 0.2270])\n",
      "mean:  tensor([0.5025, 0.4733, 0.4263])\n",
      "std:  tensor([0.2272, 0.2227, 0.2269])\n",
      "mean:  tensor([0.5030, 0.4736, 0.4266])\n",
      "std:  tens"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 4000 exceeded with 4029 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f2fef76142d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#if i%10==0: print(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch size (the last batch can have smaller size!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \"\"\"\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = data_loader_sup_val\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "i=0\n",
    "sample_num=0\n",
    "\n",
    "for images, _ in loader:\n",
    "    #if i%10==0: print(10)\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    \n",
    "    sample_num+=batch_samples\n",
    "    print('mean: ',mean/sample_num)\n",
    "    print('std: ',std/sample_num)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:28:31.984321Z",
     "start_time": "2019-05-01T21:25:51.177779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor([0.5099, 0.4805, 0.4300])\n",
      "std:  tensor([0.2306, 0.2213, 0.2273])\n",
      "mean:  tensor([0.4942, 0.4704, 0.4167])\n",
      "std:  tensor([0.2238, 0.2170, 0.2218])\n",
      "mean:  tensor([0.4969, 0.4716, 0.4221])\n",
      "std:  tensor([0.2256, 0.2199, 0.2235])\n",
      "mean:  tensor([0.5024, 0.4748, 0.4235])\n",
      "std:  tensor([0.2249, 0.2204, 0.2240])\n",
      "mean:  tensor([0.5040, 0.4758, 0.4246])\n",
      "std:  tensor([0.2240, 0.2194, 0.2225])\n",
      "mean:  tensor([0.5011, 0.4730, 0.4215])\n",
      "std:  tensor([0.2237, 0.2193, 0.2221])\n",
      "mean:  tensor([0.5031, 0.4753, 0.4225])\n",
      "std:  tensor([0.2226, 0.2184, 0.2211])\n",
      "mean:  tensor([0.5005, 0.4732, 0.4214])\n",
      "std:  tensor([0.2237, 0.2195, 0.2224])\n",
      "mean:  tensor([0.5022, 0.4748, 0.4225])\n",
      "std:  tensor([0.2223, 0.2191, 0.2222])\n",
      "mean:  tensor([0.5027, 0.4753, 0.4232])\n",
      "std:  tensor([0.2218, 0.2187, 0.2223])\n",
      "mean:  tensor([0.5037, 0.4752, 0.4231])\n",
      "std:  tensor([0.2224, 0.2193, 0.2230])\n",
      "mean:  tensor([0.5033, 0.4739, 0.4217])\n",
      "std:  tensor([0.2227, 0.2197, 0.2239])\n",
      "mean:  tensor([0.5026, 0.4733, 0.4216])\n",
      "std:  tensor([0.2224, 0.2194, 0.2232])\n",
      "mean:  tensor([0.5030, 0.4734, 0.4216])\n",
      "std:  tensor([0.2225, 0.2195, 0.2231])\n",
      "mean:  tensor([0.5012, 0.4723, 0.4218])\n",
      "std:  tensor([0.2235, 0.2199, 0.2239])\n",
      "mean:  tensor([0.5010, 0.4733, 0.4223])\n",
      "std:  tensor([0.2236, 0.2199, 0.2243])\n",
      "mean:  tensor([0.5022, 0.4741, 0.4235])\n",
      "std:  tensor([0.2240, 0.2203, 0.2248])\n",
      "mean:  tensor([0.5018, 0.4736, 0.4222])\n",
      "std:  tensor([0.2243, 0.2203, 0.2248])\n",
      "mean:  tensor([0.5031, 0.4739, 0.4224])\n",
      "std:  tensor([0.2242, 0.2200, 0.2245])\n",
      "mean:  tensor([0.5031, 0.4735, 0.4222])\n",
      "std:  tensor([0.2241, 0.2199, 0.2241])\n",
      "mean:  tensor([0.5037, 0.4743, 0.4226])\n",
      "std:  tensor([0.2243, 0.2201, 0.2242])\n",
      "mean:  tensor([0.5050, 0.4755, 0.4243])\n",
      "std:  tensor([0.2245, 0.2203, 0.2243])\n",
      "mean:  tensor([0.5043, 0.4749, 0.4239])\n",
      "std:  tensor([0.2249, 0.2207, 0.2246])\n",
      "mean:  tensor([0.5049, 0.4751, 0.4243])\n",
      "std:  tensor([0.2247, 0.2205, 0.2245])\n",
      "mean:  tensor([0.5048, 0.4752, 0.4251])\n",
      "std:  tensor([0.2247, 0.2206, 0.2247])\n",
      "mean:  tensor([0.5044, 0.4752, 0.4250])\n",
      "std:  tensor([0.2248, 0.2208, 0.2250])\n",
      "mean:  tensor([0.5047, 0.4757, 0.4252])\n",
      "std:  tensor([0.2251, 0.2209, 0.2249])\n",
      "mean:  tensor([0.5052, 0.4763, 0.4254])\n",
      "std:  tensor([0.2247, 0.2206, 0.2247])\n",
      "mean:  tensor([0.5053, 0.4764, 0.4256])\n",
      "std:  tensor([0.2244, 0.2204, 0.2245])\n",
      "mean:  tensor([0.5053, 0.4760, 0.4251])\n",
      "std:  tensor([0.2249, 0.2207, 0.2247])\n",
      "mean:  tensor([0.5055, 0.4762, 0.4251])\n",
      "std:  tensor([0.2250, 0.2208, 0.2245])\n",
      "mean:  tensor([0.5055, 0.4761, 0.4247])\n",
      "std:  tensor([0.2244, 0.2205, 0.2243])\n",
      "mean:  tensor([0.5059, 0.4767, 0.4253])\n",
      "std:  tensor([0.2243, 0.2203, 0.2242])\n",
      "mean:  tensor([0.5060, 0.4767, 0.4252])\n",
      "std:  tensor([0.2248, 0.2206, 0.2245])\n",
      "mean:  tensor([0.5054, 0.4763, 0.4249])\n",
      "std:  tensor([0.2247, 0.2206, 0.2246])\n",
      "mean:  tensor([0.5055, 0.4761, 0.4251])\n",
      "std:  tensor([0.2248, 0.2207, 0.2246])\n",
      "mean:  tensor([0.5051, 0.4758, 0.4248])\n",
      "std:  tensor([0.2249, 0.2208, 0.2245])\n",
      "mean:  tensor([0.5055, 0.4758, 0.4247])\n",
      "std:  tensor([0.2252, 0.2209, 0.2245])\n",
      "mean:  tensor([0.5059, 0.4764, 0.4251])\n",
      "std:  tensor([0.2252, 0.2210, 0.2243])\n",
      "mean:  tensor([0.5062, 0.4768, 0.4255])\n",
      "std:  tensor([0.2252, 0.2210, 0.2244])\n",
      "mean:  tensor([0.5063, 0.4769, 0.4257])\n",
      "std:  tensor([0.2255, 0.2214, 0.2246])\n",
      "mean:  tensor([0.5063, 0.4767, 0.4253])\n",
      "std:  tensor([0.2254, 0.2213, 0.2245])\n",
      "mean:  tensor([0.5062, 0.4765, 0.4252])\n",
      "std:  tensor([0.2254, 0.2213, 0.2246])\n",
      "mean:  tensor([0.5056, 0.4758, 0.4244])\n",
      "std:  tensor([0.2254, 0.2212, 0.2244])\n",
      "mean:  tensor([0.5054, 0.4757, 0.4244])\n",
      "std:  tensor([0.2255, 0.2213, 0.2246])\n",
      "mean:  tensor([0.5057, 0.4760, 0.4244])\n",
      "std:  tensor([0.2255, 0.2212, 0.2245])\n",
      "mean:  tensor([0.5056, 0.4763, 0.4249])\n",
      "std:  tensor([0.2258, 0.2216, 0.2249])\n",
      "mean:  tensor([0.5059, 0.4766, 0.4253])\n",
      "std:  tensor([0.2257, 0.2216, 0.2249])\n",
      "mean:  tensor([0.5060, 0.4766, 0.4252])\n",
      "std:  tensor([0.2256, 0.2215, 0.2249])\n",
      "mean:  tensor([0.5059, 0.4763, 0.4249])\n",
      "std:  tensor([0.2256, 0.2215, 0.2250])\n",
      "mean:  tensor([0.5062, 0.4766, 0.4255])\n",
      "std:  tens"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 4000 exceeded with 4029 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-643ce5392ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#if i%10==0: print(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch size (the last batch can have smaller size!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = data_loader_unsup\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "i=0\n",
    "sample_num=0\n",
    "\n",
    "for images, _ in loader:\n",
    "    #if i%10==0: print(10)\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    \n",
    "    sample_num+=batch_samples\n",
    "    print('mean: ',mean/sample_num)\n",
    "    print('std: ',std/sample_num)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T21:36:15.195199Z",
     "start_time": "2019-05-01T21:35:13.873197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor([0.0257, 0.0389, 0.0037])\n",
      "std:  tensor([0.9625, 0.9704, 0.9698])\n",
      "mean:  tensor([-0.0127, -0.0253, -0.0596])\n",
      "std:  tensor([1.0078, 1.0028, 0.9835])\n",
      "mean:  tensor([-0.0210, -0.0042, -0.0258])\n",
      "std:  tensor([1.0049, 1.0044, 0.9886])\n",
      "mean:  tensor([-0.0077, -0.0018, -0.0057])\n",
      "std:  tensor([1.0046, 1.0038, 0.9944])\n",
      "mean:  tensor([-0.0103, -0.0061, -0.0140])\n",
      "std:  tensor([1.0029, 1.0052, 0.9978])\n",
      "mean:  tensor([-0.0208, -0.0161, -0.0172])\n",
      "std:  tensor([0.9994, 1.0022, 1.0003])\n",
      "mean:  tensor([-0.0079, -0.0078, -0.0151])\n",
      "std:  tensor([1.0054, 1.0048, 1.0045])\n",
      "mean:  tensor([-0.0255, -0.0241, -0.0276])\n",
      "std:  tensor([1.0071, 1.0058, 1.0025])\n",
      "mean:  tensor([-0.0085, -0.0162, -0.0157])\n",
      "std:  tensor([1.0105, 1.0101, 1.0085])\n",
      "mean:  tensor([-0.0165, -0.0210, -0.0169])\n",
      "std:  tensor([1.0082, 1.0077, 1.0060])\n",
      "mean:  tensor([-0.0172, -0.0224, -0.0163])\n",
      "std:  tensor([1.0058, 1.0074, 1.0065])\n",
      "mean:  tensor([-0.0231, -0.0257, -0.0194])\n",
      "std:  tensor([1.0042, 1.0080, 1.0061])\n",
      "mean:  tensor([-0.0221, -0.0236, -0.0159])\n",
      "std:  tensor([1.0023, 1.0062, 1.0059])\n",
      "mean:  tensor([-0.0224, -0.0263, -0.0174])\n",
      "std:  tensor([1.0011, 1.0038, 1.0040])\n",
      "mean:  tensor([-0.0228, -0.0299, -0.0199])\n",
      "std:  tensor([1.0016, 1.0032, 1.0057])\n",
      "mean:  tensor([-0.0240, -0.0312, -0.0216])\n",
      "std:  tensor([1.0013, 1.0011, 1.0036])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a28bb555b360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#if i%10==0: print(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch size (the last batch can have smaller size!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test normalization\n",
    "loader_image_path='/scratch/by783/DL_Final/ssl_data_96'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.502, 0.474, 0.426], [0.227, 0.222, 0.226])])\n",
    "\n",
    "sup_train_data = datasets.ImageFolder('{}/{}/train'.format(loader_image_path, 'supervised'), transform=transform)\n",
    "sup_val_data = datasets.ImageFolder('{}/{}/val'.format(loader_image_path, 'supervised'), transform=transform)\n",
    "unsup_data = datasets.ImageFolder('{}/{}/'.format(loader_image_path, 'unsupervised'), transform=transform)\n",
    "\n",
    "data_loader_sup_train = torch.utils.data.DataLoader(\n",
    "        sup_train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "data_loader_sup_val = torch.utils.data.DataLoader(\n",
    "        sup_val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "data_loader_unsup = torch.utils.data.DataLoader(\n",
    "        unsup_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "\n",
    "loader = data_loader_sup_train\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "i=0\n",
    "sample_num=0\n",
    "\n",
    "for images, _ in loader:\n",
    "    #if i%10==0: print(10)\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    \n",
    "    sample_num+=batch_samples\n",
    "    print('mean: ',mean/sample_num)\n",
    "    print('std: ',std/sample_num)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:05.052983Z",
     "start_time": "2019-05-02T01:47:05.031651Z"
    }
   },
   "outputs": [],
   "source": [
    "class TEST(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST, self).__init__()\n",
    "        self.encoder=nn.Sequential(nn.Linear(1,1))\n",
    "        self.decoder=nn.Sequential(nn.Linear(1,1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "\n",
    "def Get_features(self, _input, _output):\n",
    "    print('print: input:',_input)\n",
    "    print('print: output:',_output)\n",
    "    #return output\n",
    "\n",
    "def Get_encoder_features(self, input_, output_):\n",
    "    encoder_output.append(output_)\n",
    "    \n",
    "def Get_decoder_features(self, input_, output_):\n",
    "    encoder_output.append(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:07.767204Z",
     "start_time": "2019-05-02T01:47:07.760897Z"
    }
   },
   "outputs": [],
   "source": [
    "x=torch.tensor([[1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:08.135216Z",
     "start_time": "2019-05-02T01:47:08.118185Z"
    }
   },
   "outputs": [],
   "source": [
    "model=TEST()\n",
    "\n",
    "# 如何重设 layer\n",
    "# https://discuss.pytorch.org/t/load-initial-weights-to-one-layer-of-the-convnet-manually/13336\n",
    "model.encoder[0].weight.data = torch.tensor([[2.0]])\n",
    "model.encoder[0].bias.data=torch.tensor([[0.0]])\n",
    "\n",
    "\n",
    "model.decoder[0].weight.data = torch.tensor([[3.0]])\n",
    "model.decoder[0].bias.data=torch.tensor([[0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:23.611972Z",
     "start_time": "2019-05-02T01:47:23.603190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2b87d929dfd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output=[]\n",
    "model.decoder[0].register_forward_hook(Get_decoder_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:24.973518Z",
     "start_time": "2019-05-02T01:47:24.969530Z"
    }
   },
   "outputs": [],
   "source": [
    "l=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:25.561643Z",
     "start_time": "2019-05-02T01:47:25.550612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[2.]], grad_fn=<ThAddmmBackward>),)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:36.330737Z",
     "start_time": "2019-05-02T01:47:36.324595Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:36.882326Z",
     "start_time": "2019-05-02T01:47:36.874609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:47:37.327086Z",
     "start_time": "2019-05-02T01:47:37.321763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T18:46:33.117785Z",
     "start_time": "2019-05-01T18:46:33.113526Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:51:19.037908Z",
     "start_time": "2019-05-02T01:51:19.022576Z"
    }
   },
   "outputs": [],
   "source": [
    "model2=TEST()\n",
    "\n",
    "# 如何重设 layer\n",
    "# https://discuss.pytorch.org/t/load-initial-weights-to-one-layer-of-the-convnet-manually/13336\n",
    "model2.encoder[0].weight.data = torch.tensor([[2.0]])\n",
    "model2.encoder[0].bias.data=torch.tensor([[0.0]])\n",
    "\n",
    "\n",
    "model2.decoder[0].weight.data = torch.tensor([[3.0]])\n",
    "model2.decoder[0].bias.data=torch.tensor([[0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:51:19.369590Z",
     "start_time": "2019-05-02T01:51:19.357447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2b87d92992b0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output=[]\n",
    "model2.decoder[0].register_forward_hook(Get_decoder_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:51:19.836122Z",
     "start_time": "2019-05-02T01:51:19.832256Z"
    }
   },
   "outputs": [],
   "source": [
    "l=model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:52:58.870038Z",
     "start_time": "2019-05-02T01:52:58.861806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.]], grad_fn=<ThAddmmBackward>),)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:52:06.118497Z",
     "start_time": "2019-05-02T01:52:06.113288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:51:24.509722Z",
     "start_time": "2019-05-02T01:51:24.497829Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() received an invalid combination of arguments - got (tuple), but expected one of:\n * (Tensor other, Number alpha)\n * (Number other, Number alpha)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-605b9dbf8915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: add() received an invalid combination of arguments - got (tuple), but expected one of:\n * (Tensor other, Number alpha)\n * (Number other, Number alpha)\n"
     ]
    }
   ],
   "source": [
    "l=l+encoder_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T01:49:43.849521Z",
     "start_time": "2019-05-02T01:49:43.845099Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T22:14:33.007975Z",
     "start_time": "2019-05-01T22:14:33.003101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.encoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T22:14:33.187885Z",
     "start_time": "2019-05-01T22:14:33.182954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.decoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the hook works, can extract the layer vaild layer output ('True' layer output, which remember its position in the computational graph and correctly calculate the grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:03:37.700786Z",
     "start_time": "2019-05-01T19:03:37.697567Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.670364Z",
     "start_time": "2019-05-01T19:04:19.666885Z"
    }
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "stop here",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m stop here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bixing/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit('stop here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:02:27.207311Z",
     "start_time": "2019-05-01T19:02:27.064302Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.687089Z",
     "start_time": "2019-05-01T19:04:19.175Z"
    }
   },
   "outputs": [],
   "source": [
    "en_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.158785Z",
     "start_time": "2019-05-01T16:51:38.155539Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.688167Z",
     "start_time": "2019-05-01T19:04:19.178Z"
    }
   },
   "outputs": [],
   "source": [
    "model.encoder[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.167235Z",
     "start_time": "2019-05-01T16:51:38.165616Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.171297Z",
     "start_time": "2019-05-01T16:51:38.168872Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.175203Z",
     "start_time": "2019-05-01T16:51:38.172586Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.179803Z",
     "start_time": "2019-05-01T16:51:38.177013Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:51:38.183315Z",
     "start_time": "2019-05-01T16:51:38.181016Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.689406Z",
     "start_time": "2019-05-01T19:04:19.184Z"
    }
   },
   "outputs": [],
   "source": [
    "l=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.690716Z",
     "start_time": "2019-05-01T19:04:19.186Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.691763Z",
     "start_time": "2019-05-01T19:04:19.187Z"
    }
   },
   "outputs": [],
   "source": [
    "model.decoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.693088Z",
     "start_time": "2019-05-01T19:04:19.189Z"
    }
   },
   "outputs": [],
   "source": [
    "de_layer=model.decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.693901Z",
     "start_time": "2019-05-01T19:04:19.191Z"
    }
   },
   "outputs": [],
   "source": [
    "en_layer=model.encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.694697Z",
     "start_time": "2019-05-01T19:04:19.193Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "de_layer.register_forward_hook(Get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:03:27.354305Z",
     "start_time": "2019-05-01T17:03:27.350851Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:05:11.650477Z",
     "start_time": "2019-05-01T17:05:11.642418Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T19:04:19.695392Z",
     "start_time": "2019-05-01T19:04:19.197Z"
    }
   },
   "outputs": [],
   "source": [
    "l=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T22:08:01.061268Z",
     "start_time": "2019-05-01T22:08:01.056677Z"
    }
   },
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T22:08:09.925436Z",
     "start_time": "2019-05-01T22:08:09.914579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
